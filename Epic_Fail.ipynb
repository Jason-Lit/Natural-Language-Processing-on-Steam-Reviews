{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpaWoGF5pzHiJAU8zQhgKD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-6uYEjSML5o",
        "outputId": "911cb7a6-e7c5-4e63-d5b5-c22c1e7c32f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/Shared drives/MSIS 2534 - NLP Group/Final Project/David\\'s run/fine_tuned_gpt2_model'"
      ],
      "metadata": {
        "id": "gY_3raQqMyAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(file_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(file_path)"
      ],
      "metadata": {
        "id": "7lWkOrQCMUqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(review_text):\n",
        "    # Construct a prompt/question\n",
        "    prompt = f\"What game is closest to this review: {review_text}?\"\n",
        "\n",
        "    # Tokenize and encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    output = model.generate(input_ids, max_length=200, num_beams=5, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
        "\n",
        "    # Decode the generated response\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Example review text\n",
        "review_text = \"This game is amazing! The graphics are stunning, and the gameplay is smooth.\"\n",
        "\n",
        "# Generate and print the response\n",
        "response = generate_response(review_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAzutygPNIHY",
        "outputId": "3761e835-7619-4513-d7d5-a78ba3c93429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response: What game is closest to this review: This game is amazing! The graphics are stunning, and the gameplay is smooth.?.???????????????????????????????????????????????????????????????????????????????????? wonder wonder wondered wondered wondering wondering wondered dreamed dreamed imagined imagined envisioned envisioned envision envision imagine imagineImagineImagine Imagine ImagineImagine imagine suppose suppose assume assume presume presume assume expect expect anticipate anticipate foresee foresee predict predict prediction prediction predicting predicting predictions predictions forecasts forecasts projections projections forecasts forecast forecast forecasting forecasting predicting forecasting forecasts predictions projections projection projection projecting projectingprojectprojectprojectsprojects projects projects Projects ProjectsProjectProjectPropProp Prop PropPropproppropPropProProConConconconconscons cons cons Cons Cons Con Con CON CONCONCONConWinWinWINWINwinwinWinwinwinningwinningwinnerwinnerwinningwonwonlostlostLostLostMissingMissingmissingmissing missing missingmissing Missing MissingMissing missing Missing missingMissing Missing MISS MISS Miss MissMissMiss Miss miss miss misses misses missed missed missmissmiss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDJI4c3FMTom",
        "outputId": "37798c1a-b33f-415f-b265-8c0d36fddd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response: What game is closest to this review: This game is amazing! The graphics are stunning, and the gameplay is smooth.?.???????????????????????????????????????????????????????????????????????????????????? wonder wonder wondered wondered wondering wondering wondered dreamed dreamed imagined imagined envisioned envisioned envision envision imagine imagineImagineImagine Imagine ImagineImagine imagine suppose suppose assume assume presume presume assume expect expect anticipate anticipate foresee foresee predict predict prediction prediction predicting predicting predictions predictions forecasts forecasts projections projections forecasts forecast forecast forecasting forecasting predicting forecasting forecasts predictions projections projection projection projecting projectingprojectprojectprojectsprojects projects projects Projects ProjectsProjectProjectPropProp Prop PropPropproppropPropProProConConconconconscons cons cons Cons Cons Con Con CON CONCONCONConWinWinWINWINwinwinWinwinwinningwinningwinnerwinnerwinningwonwonlostlostLostLostMissingMissingmissingmissing missing missingmissing Missing MissingMissing missing Missing missingMissing Missing MISS MISS Miss MissMissMiss Miss miss miss misses misses missed missed missmissmiss\n"
          ]
        }
      ]
    }
  ]
}